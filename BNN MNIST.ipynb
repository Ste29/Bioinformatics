{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BNN MNIST.ipynb","provenance":[{"file_id":"1xiWlNxuz95I8p7T9KMezqVPKjikfFB_e","timestamp":1576847785102},{"file_id":"1DTjr4CjqzqozxVETu59U3eeLImTE5MAe","timestamp":1576170129185},{"file_id":"1XwYeDTldmj_J1fvlX1n2Nk5as-8AM1Et","timestamp":1575454002402},{"file_id":"1ToF0jRFWlgTCr_R9DAIZu7HqDQXbN0V_","timestamp":1571737170248}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"JODP_Q3mw17b","colab_type":"text"},"source":["## Install tf-gpu, imports e download dati, split train val"]},{"cell_type":"code","metadata":{"id":"5SCxiuhnwr-r","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x magic\n","from IPython.display import clear_output\n","!npm install -g localtunnel\n","%load_ext tensorboard\n","from google.colab import drive\n","drive.mount('/content/gdrive')  # Per scaricare i salvataggi\n","clear_output()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cIpfOflgDVme","colab_type":"code","outputId":"84e34011-8433-4ef1-d495-41ac0a58882a","executionInfo":{"status":"ok","timestamp":1582034399217,"user_tz":-60,"elapsed":176113,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# tf ha come requisito che gast sia > 0.2, ma l'ultima versione di gast ha un \n","# problema con autograph\n","!pip install gast==0.2.2\n","!pip install tensorflow-gpu==1.14\n","\n","\n","import os\n","from datetime import timedelta\n","import time\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","import tensorflow_probability as tfp\n","\n","tf.logging.set_verbosity(tf.logging.ERROR)  # or any {DEBUG, INFO, WARN, ERROR, FATAL}\n","\n","tfd = tfp.distributions\n","\n","# Controllo della versione di tf, perché da 1/10 quella di default è la 2.0.0\n","print(tf.__version__)  \n","print(tf.test.gpu_device_name())  # Controllo se colab sta usando la gpu\n","\n","# Download data\n","from keras.datasets import mnist\n","from scipy import io as spio\n","(x_train, y_train), (x_test, y_test) = mnist.load_data() # 60k - 10k\n","\n","\n","# Add a layer to represent colors, in RGB it will be 3, here it is 1 because \n","# these are grayscale images. \n","# The network needs 4 axes: Batches, height, width and layers\n","x_train = np.expand_dims(x_train, axis=3)\n","x_test = np.expand_dims(x_test, axis=3)\n","\n","#clear_output()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (0.2.2)\n","Collecting tensorflow-gpu==1.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/04/43153bfdfcf6c9a4c38ecdb971ca9a75b9a791bb69a764d652c359aca504/tensorflow_gpu-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (377.0MB)\n","\u001b[K     |████████████████████████████████| 377.0MB 44kB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.0.8)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.9.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.1.8)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (3.10.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.34.2)\n","Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n","\u001b[K     |████████████████████████████████| 491kB 40.1MB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.2.2)\n","Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.17.5)\n","Collecting tensorboard<1.15.0,>=1.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 48.2MB/s \n","\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.11.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.12.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.14) (1.27.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==1.14) (2.8.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.14) (45.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (3.2.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow-gpu==1.14) (1.0.0)\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.14.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorflow-estimator==1.15.1, but you'll have tensorflow-estimator 1.14.0 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n","  Found existing installation: tensorflow-estimator 1.15.1\n","    Uninstalling tensorflow-estimator-1.15.1:\n","      Successfully uninstalled tensorflow-estimator-1.15.1\n","  Found existing installation: tensorboard 1.15.0\n","    Uninstalling tensorboard-1.15.0:\n","      Successfully uninstalled tensorboard-1.15.0\n","Successfully installed tensorboard-1.14.0 tensorflow-estimator-1.14.0 tensorflow-gpu-1.14.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorboard"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"},{"output_type":"stream","text":["1.14.0\n","/device:GPU:0\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sl62o8-056py","colab_type":"code","outputId":"bfc7e1ce-9c63-4273-fc03-24cb573284c9","executionInfo":{"status":"ok","timestamp":1582034399219,"user_tz":-60,"elapsed":176096,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["def split_train_test(x, y, test_ratio):\n","  seed = np.random.RandomState(42)\n","  shuffled_indices  = seed.permutation(len(y))\n","  test_set_size = int(len(y) * test_ratio)\n","  test_indices = shuffled_indices[:test_set_size]\n","  train_indices = shuffled_indices[test_set_size:]\n","  print(type(test_indices))\n","  return (x[train_indices], y[train_indices]), (x[test_indices], y[test_indices])\n","\n","print(len(x_train))\n","(x_train, y_train), (x_val, y_val) = split_train_test(x_train, y_train, 0.15) \n","print(len(x_train))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["60000\n","<class 'numpy.ndarray'>\n","51000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8ct5EUDvyRtk","colab_type":"text"},"source":["## Parametri"]},{"cell_type":"code","metadata":{"id":"CPnFbuE6yLH8","colab_type":"code","colab":{}},"source":["learning_rate = default=0.0001  # Initial learning rate\n","epochs = 100  #Number of epochs to train for\n","batch_size = 1000  \n","eval_freq = 10*len(x_train)/batch_size  # validate the model every 10 epochs\n","valid_size = 1000\n","num_monte_carlo = 50  # Network draws to compute predictive probabilities\n","\n","IMAGE_SHAPE = [28, 28, 1]\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t89CGIju4hWs","colab_type":"text"},"source":["## Input pipeline"]},{"cell_type":"code","metadata":{"id":"Izj7xM1-4gg8","colab_type":"code","colab":{}},"source":["def make_generator(images, labels):\n","\n","  def _generator():\n","    for image, label in zip(images, labels):\n","      yield image, label\n","\n","  return _generator\n","\n","def build_input_pipeline(x_train, x_test, y_train, y_test,\n","                         batch_size, valid_size):\n","    \"\"\"Build an Iterator switching between train and heldout data.\"\"\"\n","  \n"," \n","    # Since this is a small and simple dataset we load the entire set in one \n","    # batch into the heldout set \n","\n","    # Converto in float \n","    x_train = x_train.astype(\"float32\")\n","    x_test = x_test.astype(\"float32\")\n","\n","    x_train /= 255\n","    x_test /= 255\n","\n","    print(\"x_train shape:\" + str(x_train.shape))\n","    print(str(x_train.shape[0]) + \" train samples\")\n","    print(str(x_test.shape[0]) + \" test samples\")\n","\n","    # Build an iterator over training batches.\n","    features_shape = [28, 28, 1]\n","    labels_shape = []\n","\n","    training_dataset = tf.data.Dataset.from_generator(\n","        make_generator(x_train, np.int32(y_train)), (tf.float32, tf.int32), \n","        (tf.TensorShape(features_shape), tf.TensorShape(labels_shape)))\n","\n","    training_dataset = training_dataset.shuffle(\n","        len(x_train), reshuffle_each_iteration=True).repeat().batch(batch_size)\n","    training_iterator = tf.data.make_one_shot_iterator(training_dataset)\n","\n","    # Build a iterator over the heldout set with batch_size=heldout_size,\n","    # i.e., return the entire heldout set as a constant.\n","  \n","    placeholder_X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n","    placeholder_y = tf.placeholder(tf.int32, [None])\n","\n","    heldout_dataset = tf.data.Dataset.from_tensor_slices((placeholder_X, \n","                                                          placeholder_y))\n","\n","    heldout_batches = heldout_dataset.repeat().batch(valid_size)  # niente reshuffle\n","    heldout_iterator = tf.data.make_initializable_iterator(heldout_batches)\n","\n","    # Combine these into a feedable iterator that can switch between training\n","    # and validation inputs.\n","    handle = tf.compat.v1.placeholder(tf.string, shape=[])\n","    feedable_iterator = tf.compat.v1.data.Iterator.from_string_handle(\n","        handle, training_dataset.output_types, training_dataset.output_shapes)\n","    images, labels = feedable_iterator.get_next()\n","\n","    return images, labels, handle, training_iterator, heldout_iterator, placeholder_X, placeholder_y"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mJa2smRJ_Q8a","colab_type":"text"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"1AXYR6_p_RoV","colab_type":"code","outputId":"43000f5b-2be1-49c1-bf95-8ab1bba6c367","executionInfo":{"status":"ok","timestamp":1582034402837,"user_tz":-60,"elapsed":3390,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["from datetime import datetime\n","# Saves and logs Folder\n","now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n","root_logdir = \"/content/tf_logs\"\n","logdir = \"{}/run-{}/\".format(root_logdir,now)\n","root_savedir = \"/content/saves\"\n","\n","#Build the input pipeline\n","with tf.name_scope(\"Dataset\"):\n","  (images, labels, handle,\n","  training_iterator,\n","  heldout_iterator, X, y) = build_input_pipeline(x_train, x_val, y_train, y_val, \n","                                                 batch_size, valid_size)\n","  \n","#Build the network\n","with tf.name_scope(\"BNN\"):\n","  inputs = tf.keras.layers.Input(shape=IMAGE_SHAPE, dtype='float32')\n","  x = tfp.layers.Convolution2DFlipout(32, (5, 5), activation='relu', padding='same')(inputs)\n","  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n","  x = tfp.layers.Convolution2DFlipout(64, (5, 5), activation='relu', padding='same')(x)\n","  x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n","\n","  x = tf.keras.layers.Flatten()(x)\n","  x = tfp.layers.DenseFlipout(100, activation='relu')(x)\n","  outputs = tfp.layers.DenseFlipout(10, activation=None)(x)\n","  model = tf.keras.Model(inputs, outputs)\n","\n","logits = model(images)  #Network output before softmax\n","softmax = tf.nn.softmax(logits)  #Network output after softmax\n","\n","with tf.name_scope(\"loss\"):\n","  #Categorical distribution of probabilities for each instance\n","  labels_distribution = tfd.Categorical(logits=logits)    \n","  \n","  # Compute the -ELBO as the loss.\n","\n","  log_likelihood = labels_distribution.log_prob(labels)  # Probability Mass Function (PMF) of each instance\n","  neg_log_likelihood = -tf.reduce_mean(input_tensor=log_likelihood)\n","  kl = sum(model.losses) / len(x_train) \n","  loss = neg_log_likelihood + kl\n","  \n","# Build metrics for evaluation. Predictions are formed from a single forward\n","# pass of the probabilistic layers. They are cheap but noisy\n","# predictions.\n","predictions = tf.argmax(input=logits, axis=1)\n","\n","with tf.name_scope(\"train\"):\n","  train_accuracy, train_accuracy_update_op = tf.metrics.accuracy(\n","      labels=labels, predictions=predictions)\n","  optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate)\n","  train_op = optimizer.minimize(loss)\n","\n","with tf.name_scope(\"valid\"):\n","  valid_accuracy, valid_accuracy_update_op = tf.metrics.accuracy(\n","      labels=labels, predictions=predictions)\n","\n","init_op = tf.group(tf.global_variables_initializer(),\n","                  tf.local_variables_initializer())  \n","\n","\n","loss_summary = tf.summary.scalar(\"loss\", loss)\n","train_acc_summary = tf.summary.scalar(\"train_acc\", train_accuracy)\n","valid_acc_summary = tf.summary.scalar(\"valid_acc\", valid_accuracy)\n","\n","file_writer = tf.summary.FileWriter(logdir, graph=tf.get_default_graph())  # save graph\n","\n","stream_vars_train = [\n","    v for v in tf.local_variables() if \"train/\" in v.name]\n","reset_train_op = tf.compat.v1.variables_initializer(stream_vars_train)\n","\n","stream_vars_valid = [\n","    v for v in tf.local_variables() if \"valid/\" in v.name]\n","reset_valid_op = tf.compat.v1.variables_initializer(stream_vars_valid)\n","\n","saver = tf.train.Saver()  # save node\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["x_train shape:(51000, 28, 28, 1)\n","51000 train samples\n","9000 test samples\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-4mWx3yRK0KS","colab_type":"text"},"source":["## Execution phase"]},{"cell_type":"code","metadata":{"id":"OT-m8FXNK0Uo","colab_type":"code","colab":{}},"source":["with tf.Session() as sess:\n","    sess.run(init_op)\n","\n","    # Run the training loop\n","\n","    train_handle = sess.run(training_iterator.string_handle())\n","    heldout_handle = sess.run(heldout_iterator.string_handle())\n","    \n","    training_steps = int(\n","        round(epochs * (len(x_train) / batch_size))) #Epochs * step per epoch\n","\n","    for step in range(training_steps):\n","        _ = sess.run([train_op, train_accuracy_update_op, update_step_op], \n","                     feed_dict={handle: train_handle})\n","\n","        #Compute, print and save accuracy every 100 steps\n","\n","        if step % 100 == 0: \n","            loss_value, accuracy_value, kl_value, summary_loss, \\\n","            summary_t_acc = sess.run([loss, train_accuracy, kl, loss_summary, \n","                                      train_acc_summary], \n","                                     feed_dict={handle: train_handle})\n","            print(\n","                \"Step: {:>3d} Loss: {:.3f} Accuracy: {:.3f} KL: {:.3f}\".format(\n","                    step, loss_value, accuracy_value, kl_value))\n","            file_writer.add_summary(summary_loss, step)\n","            file_writer.add_summary(summary_t_acc, step)\n","            sess.run(reset_train_op)\n","\n","        #Save the model every 2000 steps\n","        if (step) % 2000 == 0:\n","            savedir = \"{}/run-{}/\".format(root_savedir,now)\n","            salvataggio = savedir + \"bio.ckpt\"\n","\n","            if tf.io.gfile.exists(savedir):\n","                tf.compat.v1.logging.warning(\n","                    \"Warning: deleting old log directory at {}\".format(savedir))\n","                tf.io.gfile.rmtree(savedir)\n","                \n","            tf.io.gfile.makedirs(savedir)\n","\n","            save_path = saver.save(sess, salvataggio)   \n","\n","\n","        #Validate the model and print and save the validation accuracy every 100 steps \n","        if (step) % 100 == 0:\n","\n","            for n in range(int(len(y_val)/valid_size)): #Validate using batches of valid_size\n","                sess.run(heldout_iterator.initializer, \n","                         feed_dict = {handle: heldout_handle,\n","                                      X: x_val_norm[n*valid_size:(n+1)*valid_size,:,:,:],\n","                                      y: y_val[n*valid_size:(n+1)*valid_size]})\n","                \n","                sess.run(valid_accuracy_update_op, \n","                         feed_dict={handle: heldout_handle})\n","                \n","                \n","            valid_value, summary_v_acc = sess.run([valid_accuracy, \\\n","                                                   valid_acc_summary], \n","                                                  feed_dict={handle: heldout_handle})\n","            \n","            print(\" ... Validation Accuracy: {:.3f}\".format(valid_value))\n","            file_writer.add_summary(summary_v_acc, step)\n","            sess.run(reset_valid_op)\n","\n","file_writer.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"szI327PT0mbu","colab_type":"text"},"source":["## Tensorboard"]},{"cell_type":"code","metadata":{"id":"rc-OX9Fv2NJv","colab_type":"code","colab":{}},"source":["#Display tensorboard\n","%tensorboard --logdir \"/content/gdrive/My Drive/BIOINFORMATICS - Project 7.1/MNIST/BNN MNIST/tf_logs/\" --port 8008 --reload_interval 2\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"egjy0yaMyLe_","colab_type":"text"},"source":["## emnist"]},{"cell_type":"code","metadata":{"id":"Gx2HfomVKs4j","colab_type":"code","outputId":"cfbd3959-b369-4f1d-e1f6-2b4169d863b7","executionInfo":{"status":"ok","timestamp":1582034428464,"user_tz":-60,"elapsed":29004,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["# Download EMNIST dataset\n","!wget http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip\n","!unzip matlab.zip\n","emnist = spio.loadmat(os.path.join(\"matlab\", \"emnist-letters\"))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-02-18 14:00:04--  http://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip\n","Resolving www.itl.nist.gov (www.itl.nist.gov)... 129.6.13.51, 2610:20:6b01:4::36\n","Connecting to www.itl.nist.gov (www.itl.nist.gov)|129.6.13.51|:80... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip [following]\n","--2020-02-18 14:00:04--  https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/matlab.zip\n","Connecting to www.itl.nist.gov (www.itl.nist.gov)|129.6.13.51|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 743900280 (709M) [application/zip]\n","Saving to: ‘matlab.zip’\n","\n","matlab.zip          100%[===================>] 709.44M  47.8MB/s    in 16s     \n","\n","2020-02-18 14:00:21 (43.3 MB/s) - ‘matlab.zip’ saved [743900280/743900280]\n","\n","Archive:  matlab.zip\n","  inflating: matlab/emnist-balanced.mat  \n","  inflating: matlab/emnist-byclass.mat  \n","  inflating: matlab/emnist-bymerge.mat  \n","  inflating: matlab/emnist-digits.mat  \n","  inflating: matlab/emnist-letters.mat  \n","  inflating: matlab/emnist-mnist.mat  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B3n2Zid7xOkq","colab_type":"code","colab":{}},"source":["x_train2 = emnist[\"dataset\"][0][0][0][0][0][0]\n","x_train2 = np.squeeze(x_train2.astype(np.float32))\n","y_train2 = np.squeeze(emnist[\"dataset\"][0][0][0][0][0][1])\n","x_test2 = emnist[\"dataset\"][0][0][1][0][0][0]\n","x_test2 = x_test2.astype(np.float32)\n","y_test2 = np.squeeze(emnist[\"dataset\"][0][0][1][0][0][1])\n","x_train2 /= 255\n","x_test2 /= 255\n","x_train2 = x_train2.reshape(x_train2.shape[0], 28, 28, order=\"A\")\n","x_test2 = x_test2.reshape(x_test2.shape[0], 28, 28, order=\"A\")\n","\n","x_val2 = np.expand_dims(x_test2, axis=3) \n","fake_labels = np.zeros((len(x_test2), 10))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hw8HprE4LA0i","colab_type":"code","outputId":"03d06c8b-0a7d-4f62-ef3f-73d3087c4973","executionInfo":{"status":"ok","timestamp":1582034458431,"user_tz":-60,"elapsed":549,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["n_emnist=205\n","\n","print(chr(y_test2[n_emnist]+64))\n","plt.figure(figsize=(5, 3))\n","img=plt.imshow(np.squeeze(x_test2[n_emnist]), cmap='Greys')\n","plt.title('Image')\n","plt.grid(False)\n","plt.xticks([])\n","plt.yticks([])\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["A\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAALQAAADECAYAAAA27wvzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCoVGKBQaoVBohPI/PDmlgJR9Tc0AAAAASUVORK5CYII=\n","text/plain":["<Figure size 360x216 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7Th4G8xA8mYg","colab":{}},"source":["#Function which computes uncertainty\n","def compute_uncertainty(x,label,valid_size):\n","    with tf.Session() as sess:\n","        #Restore trained model\n","        sess.run(init_op)\n","        saver.restore(sess,\"/content/gdrive/My Drive/BIOINFORMATICS - Project 7.1/MNIST/BNN MNIST/tf_saves/mnist.ckpt\")\n","        sess.run(reset_valid_op)\n","\n","        num_monte_carlo = 50 #Number of inferences\n","        threshold = 0.15 #Images with uncertainty > threshold are considered uncertain\n","        \n","        #Lists used to store data about all the images. In particular:\n","        aleatoric_def = [] #Stores aleatoric uncertainty\n","        epistemic_def = [] #Stores epistemic uncertainty\n","        wrong = [] #Stores index of wrong predictions\n","        predicted_as = [] #Stores the prediction label (not always correct)\n","\n","        counter = [0,0,0,0] #right, wrong, skipped right, skipped wrong\n","\n","        heldout_handle = sess.run(heldout_iterator.string_handle())\n","\n","        for n in range(int(len(label)/valid_size)): #For each batch of valid_size\n","            sess.run(heldout_iterator.initializer, \n","                        feed_dict = {handle: heldout_handle,\n","                                    X: x[n*valid_size:(n+1)*valid_size,:,:,:],\n","                                    y: label[n*valid_size:(n+1)*valid_size]})\n","\n","            sess.run(valid_accuracy_update_op, \n","                        feed_dict={handle: heldout_handle})\n","            \n","            #Uncertainty computation\n","            probs = np.asarray([sess.run(labels_distribution.probs,\n","                                feed_dict={handle: heldout_handle})\n","                        for _ in range(num_monte_carlo)])\n","            \n","            # probs has dimensions: [num_montecarlo, valid_size, num_classes]\n","\n","            for i in range(valid_size): #For each image in the current batch:\n","                predicted_class = np.argmax(np.mean(probs[:,i,:],axis=0)) #Class with highest probability\n","                if predicted_class != label[n*valid_size+i]:\n","                    wrong.append(n*valid_size + i)  #Wrong prediction\n","\n","                phat = probs[:,i,:] #dimensions: [num_monte_carlo, num_classes]\n","                psigned = np.mean(probs[:,i,:],axis=0) #dimensions: [num_classes]\n","\n","                aleatoric = 0\n","                epistemic = 0\n","                for t in range(num_monte_carlo): #For each inference\n","                    aleatoric += phat[t,predicted_class] - (phat[t,predicted_class])**2 #Compute aleatoric uncertainty\n","                    epistemic += (phat[t,predicted_class] - psigned[predicted_class])**2 #Compute epistemic uncertainty\n","                aleatoric/=num_monte_carlo #Mean aleatoric uncertainty over num_monte_carlo inferences\n","                epistemic/=num_monte_carlo #Mean epistemic uncertainty over num_monte_carlo inferences\n"," \n","                aleatoric_def.append(aleatoric)\n","                epistemic_def.append(epistemic)\n","                predicted_as.append(predicted_class)\n","\n","                #Update variables to print new accuracies\n","                if aleatoric+epistemic > threshold: #Uncertain\n","                  if predicted_class == label[n*valid_size+i]: #Uncertain but it was right\n","                    counter[2]+=1\n","                  else: #Uncertain and it was wrong\n","                    counter[3]+=1\n","                elif predicted_class == label[n*valid_size+i]:  #Not uncertain and right prediction\n","                  counter[0]+=1\n","                else: #Not uncertain and wrong prediction\n","                  counter[1]+=1\n","                  \n","        valid_value = sess.run(valid_accuracy, feed_dict={handle: heldout_handle})\n","\n","        print(\" ... Validation Accuracy: {:.3f}\".format(valid_value))\n","        print(\"Right predicted: {:.2f}% , Wrong predicted: {:.2f}% , Unpredicted : {:.2f}%\".format(100*(counter[0]/sum(counter)),100*(counter[1]/sum(counter)),100*((counter[2]+counter[3])/sum(counter))))\n","        print(\"Right unpredicted {:.2f}%, wrong unpredicted {:.2f}%\".format(100*counter[2]/(counter[2]+counter[3]),100*counter[3]/(counter[2]+counter[3])))\n","        print(\"Accuracy on predicted: {:.2f}%\".format(100*(counter[0]/(counter[0]+counter[1]))))\n","        sess.run(reset_valid_op)\n","\n","    return np.array(aleatoric_def), np.array(epistemic_def), np.array(predicted_as), np.array(wrong)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RVoXl5aOiQrV","colab_type":"code","colab":{}},"source":["def show_uncertainty(index, x, y, aleatoric, epistemic, predicted_as, isEmnist=True):\n","    \n","    if isEmnist:\n","        label = chr(y[index]+64)\n","    else:\n","        label = y[index]\n","\n","    print(label, \" predicted as \", predicted_as[index], \"with uncertainty %.2f%%\"%(100*(aleatoric[index]+ epistemic[index])))\n","    print(\"Aleatoric: %.2f%%\\tEpistemic: %.2f%%\"%(100*aleatoric[index],100*epistemic[index]))\n","\n","    plt.figure(figsize=(5, 3))\n","    img=plt.imshow(np.squeeze(x[index]), cmap='Greys')\n","    plt.title('Image')\n","    plt.grid(False)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qe7MEmcVmsdE","colab_type":"code","colab":{}},"source":["isEmnist = False\n","\n","if isEmnist:\n","    x_load = x_val2 \n","    y_load = y_test2\n","else:\n","    x_load = x_test\n","    x_load.astype(np.float32)\n","    x_load = x_load/255\n","    y_load = y_test"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"ee2c089a-0668-412d-e276-57a217158278","executionInfo":{"status":"ok","timestamp":1582034644409,"user_tz":-60,"elapsed":34733,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"id":"WfdsQRyWax9l","colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["aleatoric, epistemic, predicted_as, wrong = compute_uncertainty(x_load, y_load, valid_size)"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" ... Validation Accuracy: 0.986\n","Right predicted: 97.34% , Wrong predicted: 0.07% , Unpredicted : 2.59%\n","Right unpredicted 77.99%, wrong unpredicted 22.01%\n","Accuracy on predicted: 99.93%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"09KBrFg1OPOK","colab_type":"code","outputId":"aa9cd4d9-f593-4448-a04e-9e93fe3e0afc","executionInfo":{"status":"ok","timestamp":1581958622684,"user_tz":-60,"elapsed":1309,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["print(wrong)  # wrong predictions"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[ 340  582  619  674  740  813  947 1014 1112 1182 1226 1242 1247 1393\n"," 1530 1709 1878 1901 2035 2043 2118 2129 2130 2135 2182 2293 2387 2414\n"," 2454 2462 2488 2597 2654 2896 2939 2995 3073 3225 3422 3503 3520 3558\n"," 3727 3762 3767 3806 3808 3893 4176 4224 4256 4536 4740 4761 4823 5654\n"," 5937 5955 5973 6572 6576 6597 6651 6783 7216 8325 8408 9009 9530 9664\n"," 9729 9770]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nnrhW0PFkMMl","colab_type":"code","outputId":"b401a9b0-91c9-474a-cfe1-79291d6f9d90","executionInfo":{"status":"ok","timestamp":1582035220780,"user_tz":-60,"elapsed":495,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":249}},"source":["show_uncertainty(2597, x_load, y_load, aleatoric, epistemic, predicted_as, isEmnist)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["5  predicted as  3 with uncertainty 16.02%\n","Aleatoric: 6.50%\tEpistemic: 9.52%\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAALQAAADECAYAAAA27wvzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqVxF5aAdMgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 360x216 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"9R10oM7chAUl","colab_type":"code","outputId":"9a0026fa-8763-4bd3-96fe-f871cc3367a7","executionInfo":{"status":"ok","timestamp":1581932633672,"user_tz":-60,"elapsed":658,"user":{"displayName":"Stefano Villata","photoUrl":"","userId":"07054100665848574913"}},"colab":{"base_uri":"https://localhost:8080/","height":444}},"source":["# Unpredicted images\n","\n","unpredicted = (aleatoric + epistemic) > 0.15\n","(np.where(unpredicted))"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([  62,   92,  151,  247,  320,  340,  359,  445,  448,  449,  495,\n","         551,  582,  583,  619,  625,  659,  674,  684,  691,  716,  717,\n","         720,  740,  882,  900,  938,  947,  965, 1014, 1039, 1044, 1107,\n","        1112, 1182, 1226, 1232, 1242, 1247, 1260, 1299, 1319, 1326, 1364,\n","        1393, 1403, 1414, 1500, 1522, 1527, 1530, 1549, 1553, 1554, 1559,\n","        1601, 1621, 1681, 1709, 1737, 1790, 1828, 1868, 1878, 1900, 1954,\n","        1955, 1982, 2001, 2018, 2035, 2043, 2070, 2098, 2109, 2118, 2129,\n","        2135, 2182, 2185, 2224, 2266, 2293, 2329, 2343, 2369, 2387, 2406,\n","        2414, 2454, 2462, 2488, 2582, 2607, 2648, 2659, 2720, 2742, 2769,\n","        2770, 2771, 2810, 2896, 2921, 2927, 2939, 2953, 2959, 2995, 3005,\n","        3060, 3073, 3100, 3225, 3289, 3330, 3422, 3441, 3451, 3475, 3503,\n","        3534, 3558, 3597, 3601, 3662, 3702, 3727, 3751, 3762, 3767, 3778,\n","        3780, 3806, 3838, 3850, 3853, 3869, 3893, 3906, 3926, 3941, 3951,\n","        3985, 4007, 4027, 4078, 4163, 4199, 4224, 4238, 4256, 4265, 4284,\n","        4289, 4294, 4360, 4369, 4487, 4497, 4500, 4504, 4507, 4536, 4571,\n","        4578, 4699, 4740, 4761, 4783, 4807, 4823, 4838, 4860, 4874, 4880,\n","        4911, 4966, 4978, 5201, 5246, 5268, 5331, 5642, 5654, 5749, 5936,\n","        5937, 5955, 5973, 5981, 5982, 5997, 6011, 6071, 6081, 6091, 6101,\n","        6166, 6173, 6400, 6555, 6560, 6571, 6572, 6576, 6597, 6625, 6651,\n","        6662, 6740, 6783, 6847, 7216, 7432, 7434, 7732, 7736, 7842, 7847,\n","        7856, 7899, 7915, 7928, 7990, 8094, 8246, 8316, 8325, 8326, 8332,\n","        8408, 8520, 8527, 9009, 9015, 9024, 9505, 9530, 9540, 9634, 9638,\n","        9642, 9679, 9692, 9700, 9733, 9749, 9768, 9770, 9792, 9879, 9888,\n","        9904, 9975, 9982]),)"]},"metadata":{"tags":[]},"execution_count":27}]}]}